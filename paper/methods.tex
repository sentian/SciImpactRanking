%!TEX root = main.tex
\section*{Methods}
\noindent\textbf{Data description}
We focus on authors from all fields in the top universities across the States, who have a Google Scholar account by the end of year $2016$. The dataset includes the entire citation history for each publication of these authors. This gives us $14668$ authors in total, and together they contribute to more than $1.3$ million publications that receive around $100$ million citations in total. We've used the benchmark `biology' throughout our discussion. A scholar and all her corresponding publications are flagged as being in the field of biology, if the areas of interests that she lists on Google Scholar contain any of the keywords: `biology', `genetic', `neuroscience' and `cell'. An exploratory description of the dataset is shown in figure \ref{fig:exploratory}. 

\noindent\textbf{Training the machine learning methods}
All the methods are trained in \textit{R}\supercite{RCT2019} with the help of the package \textit{mlr}\supercite{Bischl2016}, which provides a pipeline of training, validating and testing the model. LASSO, ridge, elastic net, random forest and xgbtree are inbuilt learners of the package. Gamma LASSO and deep neural network are trained using packages \textit{gamlr}\supercite{taddy2017one} and \textit{keras}\supercite{Allaire2019} respectively.

All of the machine learning methods require the tuning of hyper-parameters. The process involves deciding the searching space of parameters and evaluating the sets of parameters using the validation data. The optimal model is the one that minimizes the validation error. Table \ref{tab:hyperpara} shows the hyper-parameter(s) for each machine learning model considered in this paper. It's worth noticing that the parameter space can be huge for method like xgbtree where we have an extensive list of tunable parameters. Randomized search with multiple iterations shall be preferred over the grid search in such scenario. Another choice can be using the Bayesian optimization that searches over the parameter space based on the performance gain. Meanwhile, parallel computing can further reduce the computing time.

The data and code are publicly available at \url{https://github.com/sentian/impact-ranking}. 






